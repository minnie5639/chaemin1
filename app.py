import streamlit as st
import pandas as pd
import nltk
from spellchecker import SpellChecker
from nltk.tokenize import word_tokenize
from nltk.tokenize.treebank import TreebankWordDetokenizer
import zipfile
import io

# ----------------------------------------
# NLTK Setup
# ----------------------------------------
def ensure_nltk():
    try:
        nltk.data.find("tokenizers/punkt")
    except LookupError:
        nltk.download("punkt")

ensure_nltk()

spell = SpellChecker()
detok = TreebankWordDetokenizer()

# ----------------------------------------
# Spell-check logic
# ----------------------------------------
def process_text(text):
    tokens = word_tokenize(text)
    corrected_tokens = []
    error_count = 0

    for token in tokens:
        if token.isalpha():
            corrected = spell.correction(token)
            if corrected.lower() != token.lower():
                error_count += 1
            corrected_tokens.append(corrected)
        else:
            corrected_tokens.append(token)

    corrected_text = detok.detokenize(corrected_tokens)
    total_words = len([t for t in tokens if t.isalpha()])

    return corrected_text, error_count, total_words

# ----------------------------------------
# Streamlit UI
# ----------------------------------------
st.title("ğŸª„ Spelling Checker (Streamlit Version)")

uploaded_files = st.file_uploader(
    "í…ìŠ¤íŠ¸ íŒŒì¼(.txt)ì„ ì—¬ëŸ¬ ê°œ ì—…ë¡œë“œí•˜ì„¸ìš”",
    type=["txt"],
    accept_multiple_files=True
)

if uploaded_files:
    st.write(f"ì´ ì—…ë¡œë“œ íŒŒì¼: **{len(uploaded_files)}ê°œ**")

    results = []
    corrected_files = {}

    for file in uploaded_files:
        raw_text = file.read().decode("utf-8", errors="ignore")
        corrected_text, error_cnt, total_words = process_text(raw_text)
        error_rate = (error_cnt / total_words * 100) if total_words else 0

        results.append({
            "filename": file.name,
            "total_words": total_words,
            "error_count": error_cnt,
            "error_rate(%)": round(error_rate, 2)
        })

        corrected_files[file.name] = corrected_text

    df = pd.DataFrame(results)
    st.subheader("ğŸ“Š Summary")
    st.dataframe(df)

    csv_data = df.to_csv(index=False).encode("utf-8")
    st.download_button(
        label="ğŸ“¥ Summary CSV ë‹¤ìš´ë¡œë“œ",
        data=csv_data,
        file_name="summary.csv",
        mime="text/csv"
    )

    zip_stream = io.BytesIO()
    with zipfile.ZipFile(zip_stream, "w") as zf:
        for fname, content in corrected_files.items():
            zf.writestr(f"corrected_{fname}", content)

    st.download_button(
        label="ğŸ“¥ ìˆ˜ì •ëœ í…ìŠ¤íŠ¸ ZIP ë‹¤ìš´ë¡œë“œ",
        data=zip_stream.getvalue(),
        file_name="corrected_texts.zip",
        mime="application/zip"
    )

else:
    st.info("ì—¬ëŸ¬ ê°œì˜ .txt íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ë§ì¶¤ë²• êµì •ì´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.")
