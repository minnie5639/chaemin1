import streamlit as st
import pandas as pd
import nltk
from spellchecker import SpellChecker
from nltk.tokenize import word_tokenize
from nltk.tokenize.treebank import TreebankWordDetokenizer
from io import StringIO
import zipfile
from datetime import datetime

# ----------------------------------------
# NLTK setup
# ----------------------------------------
def ensure_nltk():
    try:
        nltk.data.find("tokenizers/punkt")
    except LookupError:
        nltk.download("punkt")

ensure_nltk()
spell = SpellChecker()
detok = TreebankWordDetokenizer()

# ----------------------------------------
# Spell-check logic
# ----------------------------------------
def process_text(text):
    tokens = word_tokenize(text)
    corrected_tokens = []
    error_count = 0

    for token in tokens:
        if token.isalpha():
            corrected = spell.correction(token)
            if corrected.lower() != token.lower():
                error_count += 1
            corrected_tokens.append(corrected)
        else:
            corrected_tokens.append(token)

    corrected_text = detok.detokenize(corrected_tokens)
    return corrected_text, error_count, len([t for t in tokens if t.isalpha()])


# ----------------------------------------
# Streamlit UI
# ----------------------------------------
st.title("ğŸª„ Spelling Checker (Streamlit Version)")

uploaded_files = st.file_uploader(
    "í…ìŠ¤íŠ¸(.txt) íŒŒì¼ ì—¬ëŸ¬ ê°œ ì—…ë¡œë“œ",
    type=["txt"],
    accept_multiple_files=True
)

if uploaded_files:
    st.write(f"ì´ ì—…ë¡œë“œ íŒŒì¼: **{len(uploaded_files)}ê°œ**")

    results = []
    zip_buffer = StringIO()
    text_outputs = {}

    for file in uploaded_files:
        raw_text = file.read().decode("utf-8", errors="ignore")
        corrected_text, err_cnt, real_words = process_text(raw_text)
        error_rate = (err_cnt / real_words * 100) if real_words else 0

        results.append({
            "filename": file.name,
            "total_words": real_words,
            "error_count": err_cnt,
            "error_rate(%)": round(error_rate, 2)
        })

        text_outputs[file.name] = corrected_text

    # Summary table
    df = pd.DataFrame(results)
    st.subheader("ğŸ“Š Summary")
    st.dataframe(df)

    # Download CSV
    csv_data = df.to_csv(index=False).encode("utf-8")
    st.download_button(
        label="ğŸ“¥ Summary CSV ë‹¤ìš´ë¡œë“œ",
        data=csv_data,
        file_name="summary.csv",
        mime="text/csv"
    )

    # Download corrected files as ZIP
    zip_bytes = None
    import io
    zip_stream = io.BytesIO()
    with zipfile.ZipFile(zip_stream, "w") as zf:
        for fname, txt in text_outputs.items():
            zf.writestr(f"corrected_{fname}", txt)

    zip_bytes = zip_stream.getvalue()

    st.download_button(
        label="ğŸ“¥ ìˆ˜ì •ëœ íŒŒì¼ ZIP ë‹¤ìš´ë¡œë“œ",
        data=zip_bytes,
        file_name="corrected_files.zip",
        mime="application/zip"
    )

else:
    st.info("ì—¬ëŸ¬ ê°œì˜ .txt íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ì˜¤íƒˆì ê²€ì‚¬ ë° êµì •ì´ ì§„í–‰ë©ë‹ˆë‹¤.")
